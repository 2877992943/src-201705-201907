# Copyright 2018 The GraphNets Authors. All Rights Reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or  implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# ============================================================================
"""Model architectures for the demos."""

from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from graph_nets import modules
from graph_nets import utils_tf
import sonnet as snt

import tensorflow as tf

NUM_LAYERS = 1  # Hard-code number of layers in the edge/node/global models.
LATENT_SIZE = 16  # Hard-code latent layer sizes for demos.
LATENT_SIZE_SMALL=4

def make_mlp_model(name='seq'):
  """Instantiates a new MLP, followed by LayerNorm.

  The parameters of each new MLP are not shared with others generated by
  this function.

  Returns:
    A Sonnet module which contains the MLP and LayerNorm.
  """
  return snt.Sequential([
      snt.nets.MLP([LATENT_SIZE] * NUM_LAYERS, activate_final=True,
                   name=name+'_mlp'
                   ),
      snt.LayerNorm(-1,True,True,
                    name=name+'_norm'
                    )###yr
  ],
    #name=name
  )


class MLPGraphIndependent(snt.Module):
  """GraphIndependent with MLP edge, node, and global models."""

  def __init__(self, name="MLPGraphIndependent"):
    super(MLPGraphIndependent, self).__init__(name=name)
    #with self._enter_variable_scope():
    if 2>1:
    #with tf.compat.v1.variable_scope(name):
      self._network = modules.GraphIndependent(
          edge_model_fn=make_mlp_model('edge'),
          node_model_fn=make_mlp_model('node'),
          global_model_fn=make_mlp_model('global'),

      )

  def __call__(self, inputs):
    return self._network(inputs)


class MLPGraphNetwork(snt.Module):
  """GraphNetwork with MLP edge, node, and global models."""

  def __init__(self, name="MLPGraphNetwork"):
    super(MLPGraphNetwork, self).__init__(name=name)
    #with self._enter_variable_scope():
    if 2>1:
      self._network = modules.GraphNetwork(make_mlp_model('edge'),
                                           make_mlp_model('node'),
                                           make_mlp_model('global'),
                                           #name=name
                                           )

  def __call__(self, inputs):
    return self._network(inputs)


class EncodeProcessDecode(snt.Module):
  """Full encode-process-decode model.

  The model we explore includes three components:
  - An "Encoder" graph net, which independently encodes the edge, node, and
    global attributes (does not compute relations etc.).
  - A "Core" graph net, which performs N rounds of processing (message-passing)
    steps. The input to the Core is the concatenation of the Encoder's output
    and the previous output of the Core (labeled "Hidden(t)" below, where "t" is
    the processing step).
  - A "Decoder" graph net, which independently decodes the edge, node, and
    global attributes (does not compute relations etc.), on each message-passing
    step.

                      Hidden(t)   Hidden(t+1)
                         |            ^
            *---------*  |  *------*  |  *---------*
            |         |  |  |      |  |  |         |
  Input --->| Encoder |  *->| Core |--*->| Decoder |---> Output(t)
            |         |---->|      |     |         |
            *---------*     *------*     *---------*
  """

  def __init__(self,
               edge_output_size=None,
               node_output_size=None,
               global_output_size=None,
               name="EncodeProcessDecode",
               VOCABSZ_SYMPTOM=1000):
    super(EncodeProcessDecode, self).__init__(name=name)

    ## embed layer
    self._embed_mod_symptomNode = snt.Embed(
        vocab_size=VOCABSZ_SYMPTOM, embed_dim=LATENT_SIZE, name='symptomNode')
    # self._embed_mod_ageGender=snt.Embed(
    #   vocab_size=VOCABSZ_AGEGENDER, embed_dim=LATENT_SIZE/2,name='ageGender')
    self._embed_mod_global = snt.Embed(
        vocab_size=1, embed_dim=LATENT_SIZE_SMALL, name='global')
    self._embed_mod_edge = snt.Embed(
        vocab_size=1, embed_dim=LATENT_SIZE_SMALL, name='edge')


    self._encoder = MLPGraphIndependent(name='enc')
    self._core = MLPGraphNetwork(name='core')
    self._decoder = MLPGraphIndependent(name='dec')
    # Transforms the outputs into the appropriate shapes.
    if edge_output_size is None:
      edge_fn = None
    else:
      #edge_fn = lambda: snt.Linear(edge_output_size, name="edge_output")
      edge_fn = snt.Linear(edge_output_size, name="edge_output")
    if node_output_size is None:
      node_fn = None
    else:
      #node_fn = lambda: snt.Linear(node_output_size, name="node_output")
      node_fn =  snt.Linear(node_output_size, name="node_output")
    if global_output_size is None:
      global_fn = None
    else:
      #global_fn = lambda: snt.Linear(global_output_size, name="global_output")
      global_fn =  snt.Linear(global_output_size, name="global_output")
    #with self._enter_variable_scope():
    with tf.compat.v1.variable_scope("out_transform"):
    #if 2>1:
      self._output_transform = modules.GraphIndependent(edge_fn,
                                                        node_fn,
                                                        global_fn,
                                                        #name='out_transform'
                                                        )

  def __call__(self, input_op, num_processing_steps):
    ####
    fea1 = input_op.nodes[:, 0]
    fea2 = input_op.globals[:, 0]
    fea3 = input_op.edges[:, 0]
    embed1 = self._embed_mod_symptomNode(fea1)  # node
    embed2 = self._embed_mod_global(fea2)  # global
    embed3 = self._embed_mod_edge(fea3)  # edge

    embed1 = tf.cast(embed1, tf.float64)
    embed2 = tf.cast(embed2, tf.float64)
    embed3 = tf.cast(embed3, tf.float64)
    input_op = input_op.replace(nodes=embed1,
                                globals=embed2,
                                edges=embed3)  # node [? 256] edge [?,]
    ###3
    latent = self._encoder(input_op)
    #ws = self.trainable_variables
    latent0 = latent
    output_ops = []
    for _ in range(num_processing_steps):
      core_input = utils_tf.concat([latent0, latent], axis=1)
      latent = self._core(core_input)
      #ws = self.trainable_variables
      decoded_op = self._decoder(latent)
      #ws = self.trainable_variables
      output_ops.append(self._output_transform(decoded_op))
      ###
      #ws=self.trainable_variables
    return output_ops
